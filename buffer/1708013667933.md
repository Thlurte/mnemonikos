There are two organizational RAG paradigms. The first involves adding or replacing modules, while the second focuses on adjusting the organizational flow between modules.

*Adding or Replacing Modules*. The strategy of introducing or substituting modules involves maintaining the core structure of the Retrieval-Read process while integrating additional modules to enhance specific functionalities.

> [!example]
> The RRR model[^1] introduces the Rewrite-RetrieveRead process, utilizing the LLM performance as a reinforcement learning incentive for a rewriting module. This enables the rewriter to fine-tune retrieval queries, thereby improving the downstream task performance of the reader.

> [!example]
> Modules can be selectively swapped in methodologies like Generate-Read [^2], where LLM’s generation module takes the place of the retrieval module.

> [!example]
> The Recite-Read approach [^3] transforms external retrieval into retrieval from model weights, requiring the LLM to initially memorize task-specific information and subsequently produce output capable of handling knowledge-intensive natural language processing tasks.

*Adjusting the Flow between Modules*: This is about focusing on enhancing the interaction between language models and retrieval models.

> [!example]
> DSP [^4] introduces the DemonstrateSearch-Predict framework, treating the context learning system as an explicit program rather than a final task prompt, leading to more effective handling of knowledge-intensive tasks.

> [!example]
> The ITER-RETGEN [^5] approach utilizes generated content to guide retrieval, iteratively implementing “retrieval-enhanced generation” and “generationenhanced retrieval” within a Retrieve-Read-Retrieve-Read flow. This method demonstrates an innovative way of using one module’s output to improve the functionality of another.

[^5]:Z. Shao, Y. Gong, Y. Shen, M. Huang, N. Duan, and W. Chen, “Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy.” arXiv, Oct. 23, 2023. Available: [http://arxiv.org/abs/2305.15294](http://arxiv.org/abs/2305.15294). [Accessed: Feb. 14, 2024]

[^4]:O. Khattab _et al._, “Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP.” arXiv, Jan. 23, 2023. Available: [http://arxiv.org/abs/2212.14024](http://arxiv.org/abs/2212.14024). [Accessed: Feb. 15, 2024]
[^3]:Z. Sun, X. Wang, Y. Tay, Y. Yang, and D. Zhou, “Recitation-Augmented Language Models.” arXiv, Feb. 16, 2023. Available: [http://arxiv.org/abs/2210.01296](http://arxiv.org/abs/2210.01296). [Accessed: Feb. 15, 2024]

[^2]:W. Yu _et al._, “Generate rather than Retrieve: Large Language Models are Strong Context Generators.” arXiv, Jan. 25, 2023. Available: [http://arxiv.org/abs/2209.10063](http://arxiv.org/abs/2209.10063). [Accessed: Feb. 14, 2024]

[^1]:X. Ma, Y. Gong, P. He, H. Zhao, and N. Duan, “Query Rewriting for Retrieval-Augmented Large Language Models.” arXiv, Oct. 22, 2023. Available: [http://arxiv.org/abs/2305.14283](http://arxiv.org/abs/2305.14283). [Accessed: Feb. 13, 2024]

2024-02-15 Thursday- 21:44:27
